1.PIL/Pillow 是Python里最常用的图像处理库
Image是它最核心的模块，负责“打开、创建、修改、保存图片
用法示例：from PIL import Image
img_path="E:\\vegetable_dataset\\test\\images\\images-57_jpg.rf.41024012b677820a3529d2b16eec1643.jpg"
img=Image.open(img_path)
img.show()  #显示图片

Dataset类的使用
2.from torch.utils.data import Dataset
上面这行代码可以把它当成一句“我要自己做数据集了”的宣言
Dataset是PyTorch里“数据集的抽象父类”，只要你想“自己定义一个数据集”，就得继承这个父类Dataset
自定义数据集 = 继承 torch.utils.data.Dataset + 重写两个方法，这两个方法分别是__len__和__getitem__
__init__不是Dataset强制要求的，但在实际中几乎一定要写，用来“准备数据”，做一次性的初始化工作
__init__：一次性准备（只执行一次）
__getitem__：按需取一条（被反复调用）

3.import os：就是一句“我要和操作系统打交道了”的声明
os 模块 = Python访问文件系统/环境变量/路径的工具箱
os.path.join(a路径,b路径,c路径,...)   #根据操作系统自己拼接a,b,c...路径
os.listdir(dir_path)    #返回目录dir_path下的所有文件名和子目录名

4.数据集可以用内置__add__方法或者直接用'+'号进行拼接

TensorBoard可视化面板的使用
5.TensorBoard：
board英译：板，面板，可视化界面
TensorBoard = 训练过程的“可视化仪表盘”，用来看模型是怎么被训练出来的
TensorBoard 能看什么（常用到爆的）：
(1)loss / accuracy 曲线（最常用）
(2)模型结构图
(3)参数/梯度分布
(4)学习率、超参数
(5)图片/特征图（CV常用）
导入：from torch.utils.tensorboard import SummaryWriter
SummaryWriter的作用 = 把训练过程的数据写成文件，让TensorBoard可以读取并可视化
SummaryWriter是一个类，它定义了写日志的方法和行为（比如 add_image, add_scalar等），
writer是它的实例对象，通过它可以调用类里的方法，把训练数据记录到日志文件里
注：tensorboard本来是tensorflow中的，后来被pytorch借过来用

6.utils是pytorch的工具箱

7.在PyCharm中按住ctrl键鼠标移动到要查看的内容上可查看说明，点击可查看详细说明

8.from torch.utils.tensorboard import SummaryWriter
tensorboard --logdir=logs   #启动TensorBoard，并让它去读取logs文件夹下的事件文件
简单比喻:
SummaryWriter   #写日志的人
logs 文件夹    #日志本
tensorboard --logdir=logs  #打开仪表盘看日志
总结：代码里写writer = SummaryWriter("logs")，将日志写到logs文件夹里；命令行写tensorboard --logdir=logs，
利用tensorboard查看/可视化logs文件，首尾呼应
注：tensorboard --logdir=logs --port=1234
--port：改端口，防止6006被占用
add_scalar：把数字写进TensorBoard，让你用曲线跟踪训练指标变化
查看参数，有标题tag，纵坐标scalar_value，横坐标global_step(x轴的步数或epoch)等等

9.SummaryWriter类的一个成员方法--add_image()
作用：把训练过程中某一时刻的图片，写成日志文件保存下来，供TensorBoard之后查看和对比
它接收的图片类型只能是torch.tensor或者numpy.ndarray类型，而利用PIL处理得到的图片类型不满足要求，所以需要转换
除了必须满足上述图片类型之外，它的默认读取方式是CHW，如果是别的格式比如HWC，就需要在后面添加参数
“dataformats='HWC'”，不然会报错，相当于告诉它按什么顺序去读这三个维度
    图片tittle不变，即使把地址改成别的图片，再把步骤改为下一步，得到的结果不是覆盖而是会追加，之前的还在，
这正是TensorBoard的日志记录机制的特点，核心原因是TensorBoard是“追加日志”，不是覆盖日志”
如果想清除之前的，可以通过删除文件夹再重新创建或者创建子文件夹或者创建别的文件夹
如果只是想清除某一步的，可以通过将步数设为一样重新生成将其覆盖
注：后续在dataloader中还会用到add_images()，一个step可以将一个batch_size的一批图片上传

10.查看变量x的格式/形状：print(x.shape)
在from PIL import Image下：
获得图片数据：img=Image.open(img_path)
查看图片：img.show()

11.查看源代码：ctrl+单击
源代码很复杂的话还可以alt+7调出工具窗口查看每个类.c以及各个类对应的方法.m

transforms的使用
12.transforms其实就是一个模块，简单来说就是工具箱，里面有很多工具可以拿来使用
transforms的作用就是对数据（尤其是图片）进行预处理或增强，把原始数据转换成模型可以直接使用的格式，
可以包括类型转换、归一化、尺寸调整、数据增强等操作
工具箱里面有很多模具（类），需要实例化对象再使用，相当于利用模具打造工具
使用逻辑：tool = transforms.ToTensor()   #以class ToTensor为例
        result = tool(input)

13.为什么要将图片/数据转换为tensor类型？
因为Tensor数据类型包装了神经网络理论基础的一些参数，PyTorch的模型、操作、梯度计算都基于Tensor进行，
原始图片（PIL Image / NumPy ndarray）不能直接参与GPU运算
因此，ToTensor工具在PyTorch中是必用的

14.opencv的imread方法：
import cv2
img = cv2.imread(img_path)
作用：把磁盘上的图片读成一个NumPy数组
返回类型：numpy.ndarray      #type(img)-->numpy.ndarray

15.魔术方法：
类中定义的函数名如果是双下划线开头结尾，那这就是这个类的魔术方法
不需要通过"对象.方法()"这种方式来调用
eg:
class Person:
    def __call__(self,name):
        print("__call__"+"hello"+name)
person=Person()     #实例化对象
person("张三")       # 输出：__call__hello张三

16.transforms.Normalize(mean=[R,G,B],std=[R,G,B])的使用
mean:每个通道的均值
std:每个通道的标准差
相当于给出了三个通道的均值，对每个像素点(某行某列)，按顺序对每个通道进行归一化
因为某行某列的一个像素点实际上是由一个[R,G,B]数组组成
eg：img_tensor[:, 0, 0] = [0.6, 0.5, 0.4]  #左上角像素点
img_trans_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])
Normalize后：
R' = (0.6 - 0.485) / 0.229
G' = (0.5 - 0.456) / 0.224
B' = (0.4 - 0.406) / 0.225

17.transforms.Resize()的使用
传入参数：(H,W)，若传入(x)，等价于(x,x)即正方形裁剪
功能：调整图像的尺寸（高 × 宽）
输入：PIL/tensor类型的图片
返回：裁剪后的图片

18.transforms.Compose()的使用
功能：用来把多个transforms串联起来，输入的图像会按顺序依次经过每个transform
传参：传入的是列表，列表每个元素是一个transforms，即Compose([transforms1,transforms2,...])
本质：就是一个Python列表 + 顺序调用
需要注意的是前一个元素的输出和后一个元素的输入是否类型匹配，不匹配会报错

19.transforms.RandomCrop()的使用
传入参数：(H,W)，若传入(x)，等价于(x,x)即正方形裁剪
功能：随机裁剪图像的一块区域
裁剪框必须小于图片尺寸，否则会报错
16~19再加上transforms.ToTensor()为transforms的一些常用工具

PyTorch内置数据集
20.CIFAR-10数据集是torchvision.datasets提供的，PyTorch官方支持的几大内置数据集之一,
还有很多其他的数据集，自己可以去查，一个数据集元素的格式默认为二元组(PIL图片,类别),
可以自己设定转化方式将其转化为(tensor图片,类别)
下载数据集除了调用“torchvision.datasets.数据集名称”之外，需要传入一些参数，可以通过ctrl+p查看

21.python中的序列解包
序列解包（sequence unpacking）
就是：把一个“序列”里的多个元素，按顺序一次性赋值给多个变量
eg：a,b=(1,2)    #a=1,b=2

dataloader/数据加载器的使用
22.数据集不是一次性全部加载到神经网络中的，而是通过dataloader一批一批的加载，所以一个很重要的参数就是batch_size
dataloader必须记住的四个参数(记住这四个就够了)：
参数	            作用	        训练建议
dataset	        数据来源	     必填
batch_size      每批样本数	 32 / 64
shuffle	        是否打乱	     True
num_workers	    并行加载	     0~4
注：一个epoch = 把整个训练集完整地用了一遍
假设数据集有 10 个样本：
[0,1,2,3,4,5,6,7,8,9]
shuffle = True
#epoch=1，第一个回合
[3,7,1,9,0,4,8,2,6,5]   #打乱顺序
#假设batch_size=3
[3,7,1]
[9,0,4]
[8,2,6]
[5]   # 最后一批（可能不满，这时由另一个参数drop_last决定是否舍去）
下一个epoch打乱顺序得到的序列可能不一致，所以再切分的结果也就不一致

23.dataloader会按batch_size对图片进行打包
eg：输出单张图片
print(img)  # torch.size([3,32,32])
print(label)    # 3
但经过dataloader打包之后(batch_size=4为例)：
for data in test_loader:
    img, label = data
    print(img.shape)    #输出示例：torch.Size([4, 3, 32, 32])，表示4张图片，3通道，32*32
    print(label)        #输出示例：tensor([6, 0, 0, 9])，表示这四张图片的标签分别为6，0,0,9
可见test_loader中的一个元素实际上是四张图片打包在一起得到的(img,label分开打包在一起构成一个二元组)
即一个dataloader元素 = (img包,label包)

24."str{}".format()用法
功能：动态生成字符串，{}作为占位符发挥作用，将传入format的参数插入到{}位置
eg：for i in range(1,32)
        print("2026.1.{}".format(i))
依次输出2026.1.1，2026.1.2，...，2026.1.31

25.debug：设置断点+点击小虫，可以看到程序是怎么一步步执行的，对于理不清程序逻辑来说特别有用

搭建模型及常用的神经网络层
26.nn.Module的使用
torch.nn.Module是所有PyTorch神经网络模型的基类；
自己搭建神经网络模型需要继承这个父类；
继承之后必须重写__init__和forward两个方法
__init__：
用于初始化模型，定义层、参数（必须调用super().__init__()）
super()是用来调用父类的方法的，在重写__init__方法时需用到，通过它来调用父类nn.Module的初始化方法
forward:
定义前向传播
调用模型对象model(x)，自动执行forward(x)，无需手动调用
示例：class MyModel(nn.Module):
    def __init__(self):
        super().__init__()       # 必须调用父类初始化
        self.fc = nn.Linear(10, 1)

    def forward(self, x):        # 必须重写forward
        return self.fc(x)

    my_model=MyModel()  #实例化对象（自己搭建的神经网络）
注：在重写__init__方法时构建神经层(self.神经层名称=...)，但是不区分第几层
第几层是在重写forward()的时候体现出来的，先计算的就是第一层，其次是第二层，依此类推

27.重叠的有几个中括号就是几维矩阵
示例：([[1,2,0,3,1],
       [0,1,2,3,1]])    #二维矩阵

28.PyTorch的卷积函数“F.conv2d”
功能：对二维输入数据做卷积操作（二维卷积），常用于图像或特征图的特征提取
F是给torch.nn.functional取的别名，import torch.nn.functional as F
参数：F.conv2d(input,weight,bias,stride,padding,dilation,groups)
参数比较多，调用的时候建议结合位置传参和关键字传参
input：输入张量 (N, C_in, H, W)      # N：batch_size，C_in：通道数
weight：卷积核 (C_out, C_in, K_h, K_w)  # C_out：输出通道数，C_in：输入通道数(必须与input一致)
bias：偏置（可选）
stride：步长，单个数字x等价于(x,x),横向纵向走的步长都为x，如果stride=(1,2),则横向步长为1，纵向步长为2
padding：边缘补零，默认为0表示不补边缘
后两个不常用，暂时省略，要用自己查

29.池化层操作
对池化层操作，步长默认为池化核大小(kernel_size)
ceil_mode=False     #向下取整
ceil_mode=True      #向上取整
from torch.nn import MaxPool2d      #导入对二维数据进行最大池化操作的工具
MaxPool（最大池化）就是：在一个小窗口里，只保留“最强的那个响应”，把其余的都丢掉
这时ceil_mode决定当边界部分不足小窗口大小时，数据保留还是舍弃
注：在CNN（卷积神经网络）的池化操作里，最常用、最经典的就是：最大池化（MaxPool）
目的：在尽量不丢失“关键信息”的前提下，压缩特征图，减小计算量，让模型更稳、更快、更泛化

30.池化层输入input参数同卷积，也就是必须是四维张量，
对于二维矩阵，可通过Reshape(-1,C,H,W)的方法转化为四维张量

31.其实pytorch的输入几乎都是(N,C,H,W)格式
Pytorch官网torch.nn模块中介绍了全部的神经层用法     #nn：neural network，神经网络

32.线性层：Linear()
两个重要参数：
nn.Linear(in_features, out_features)表示：
把一个长度为in_features的向量，映射成一个长度为out_features的新向量
就是一个线性变换+偏置

33.将图像展平，平铺成一行：reshape(input,[1,1,1,-1])
更简单的方法：使用torch.flatten
相当于一个手动设置一个调用工具自动转换
后者更为常用

34.补充tensorboard的工具：add_graph(model, input_to_model)
功能：将模型的传播结构图画出来
这是一个很实用的功能！

35.常用的损失函数：
L1Loss()：平均绝对误差
参数reduction设置计算方式

MSELoss：均方误差
同样参数reduction设置计算方式

CrossEntropyLoss()：交叉熵损失函数，用于分类问题
输入数据格式为(N,Class)
也有很多其他参数，可通过官方文档查看

36.loss.backward()
让PyTorch自动做“反向传播”，把loss对所有可训练参数的梯度算出来
PyTorch会做三件事：
沿着计算图反向走
使用链式法则计算梯度
把梯度存到.grad里
注：它不会更新参数，只算梯度
优化器来做更新参数的事情
理解梯度：
假设Loss对参数w求梯度，即求导
a.梯度>0，增大w会让Loss变大，因此应该减小参数，更新参数的时候将w调小
b.梯度<0，增大w会让Loss变小，因此应该增大参数，更新参数的时候将w调大
优化器干的事情其实就是“往梯度反方向走”
示例：w.grad = -24.3
含义是：如果w增加1，loss大约减少24.3，相当于k·dx，从微分角度也好理解，不过实际上还会乘上学习率控制更新幅度

37.优化器（optimizer()）
反向传播求出梯度之后，通过优化器来更新参数，简单来说，优化器用来更新参数
主要参数有：
params（必须）：表示你要优化哪些参数，默认为全部参数
lr（learning rate，学习率）

38.完整训练流程
1.清空上一轮的梯度（必须最先做）
optimizer.zero_grad()
2.前向传播
outputs = model(inputs)
3.计算损失
loss = criterion(outputs, labels)
4.反向传播（计算当前batch的梯度）
loss.backward()
5.参数更新（用刚算出来的梯度）
optimizer.step()
注：可以设置断点调试程序来看参数更新的过程，参数存储在"data"里面，梯度存储在"grad"里面

现有网络模型的使用及修改
39.VGG是一种经典的卷积神经网络，用于图像分类
下载该模型的相关参数可自行前往PyTorch官网查询
可以对下载的模型进行迁移学习，包括添加神经层，修改指定神经层、删除神经层等操作，可见model_pretrained.py文件

40.模型的保存与读取
模型的保存：有两种方式，即直接保存模型文件、以字典形式保存模型参数
前者：torch.save(模型，保存路径+文件名)
后者（官方推荐用法）：torch.save(模型.state_dict(),保存路径+文件名)；这种保存方式有助于节省空间
对应的模型加载方式也有两种
前者：model1 = torch.load(文件路径,weights_only=False)
后者（麻烦一点，三步）：以vgg16为例
    vgg16 = torchvision.models.vgg16(pretrained=False)      #加载获得初始模型结构
    model2 = torch.load(文件路径)   #加载保存的模型参数
    vgg16.load_state_dict(model2)   #将加载的模型参数放入到模型结构中，获得所需模型
    "vgg16就变成了所需要的模型"，可通过print(vgg16)查看模型结构
补充说明：通过方式1（前者）保存和加载自己搭建的模型时，如果只是按照上述方式进行，加载步骤其实会报错，
需要把模型结构代码复制过来或者导包导入搭建模型的.py文件，确保程序能访问到该模型定义的方式，这样才不会报错
注意：方式1在加载模型时需要设置"weights_only=False"参数关闭安全检查，所以建议只对自己存的文件进行此操作
方式1的保存叫序列化，加载叫反序列化

41.item()可以把tensor数据类型转换为普通数字

42.分类问题的准确率计算（以二分类为例）
outputs = ([[0.1,0.2],
            [0.3,0.4]])
outputs.argmax(1) = preds = [1][1]      #预测结果，也就是通过argmax返回最大值下标，参数控制方向，0按列找，1按行找
targets = [0][1]    #目标结果
(preds==targets).sum() = 1      #得到预测对的个数
测试集上总的预测对的个数 / 测试集大小 = 正确率

43.在标准训练模型流程中，训练之前会加一行代码“tudui.train()”，测试之前会加“tudui.eval()”
二者的作用：其实只对某些特殊的层有用，也就是说如果模型中有这些特殊的层，那就必须写这两行代码，
分别手动将模型设为训练模式和验证模式；但是不存在这些特殊层，这么写也没有任何问题

44.可以通过导入time模块来计算模型训练花的时间
time.time()：返回当前时间，将其设置在不同地方，差值即为中间过程花的时间

45.如何调用GPU训练模型
方式1：调用".cuda()"再返回即可
作用对象：网络模型、数据（输入和标注）、损失函数
eg：tudui = tudui.cuda()         loss = loss.cuda();
    imgs = imgs.cuda();         targets = targets.cuda()
注：更好的写法是在前面加上判断语句："if torch.cuda.is_available():"
方式2（更常用）：device = torch.device("cuda")
      作用对象.to(device)
      """这样还可以指定显卡，如果电脑只有一张显卡，则device=torch.device("cuda:0")，
      指定第二张显卡：device=torch.device("cuda:1")"""
      作用的对象还是一样(模型、损失函数、数据)
注：语法糖写法-->device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

46.可以用谷歌的GPU进行训练

47.如果模型训练用的GPU，那么在验证的时候不要忘了将数据和加载的模型转到GPU
或者在加载模型的时候设置参数map_location="cpu"，将其从GPU映射到CPU，这样就能直接将数据送到CPU了
















